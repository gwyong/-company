# -*- coding: utf-8 -*-
"""riskSimilarityDetector

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U5uNyzNqzcjfKGvSYurJZaEGaHRGKy6Z

# Load CLIP (please implement in Google Chrome (Colab) environment.)
"""

! pip install ftfy regex tqdm
! pip install git+https://github.com/openai/CLIP.git

import numpy as np
import torch
import clip

print("Torch version:", torch.__version__) # PyTorch 1.7.1 or later is required
print("available CLIP models", clip.available_models())

model, preprocess = clip.load("ViT-B/32")
model.cuda().eval()
input_resolution = model.visual.input_resolution
context_length = model.context_length
vocab_size = model.vocab_size

print("Model parameters:", f"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}")
print("Input resolution:", input_resolution)
print("Context length:", context_length)
print("Vocab size:", vocab_size)

"""# Load the RISK csv file"""

import pandas as pd
from google.colab import files
files.upload() # load dfEnablon.csv file.

df = pd.read_csv("./dfEnablon.csv")
df

"""# Receiving user's inputs."""

import nltk
from nltk.tokenize import sent_tokenize
nltk.download('punkt')

from tqdm import tqdm
import time

targetCol = "Risk Description"

query = str(input())
query_tokens = clip.tokenize(query).cuda() # query_tokens has a torch of which size is [1, 77].

simScores = []
best_idx = 0
best_similarity = 0
best_sentence = ""

with torch.no_grad():
    query_features = model.encode_text(query_tokens).float() # query_feature has a torch of which size is [1, 512].
    for i in tqdm(range(len(df)), desc="Similarity computing...", mininterval=0.5):
      time.sleep(0.1)
      scores = []
      contents = df[targetCol].iloc[i]
      sentences = sent_tokenize(contents)
      for sentence in sentences:
        words = sentence.split(" ")
        if len(words) < 77:
          sent_tokens = clip.tokenize(sentence).cuda()
          sent_features = model.encode_text(sent_tokens).float()
          similarity = (query_features.cpu().numpy() @ sent_features.cpu().numpy().T)[0][0]
          scores.append(similarity)
          if similarity > best_similarity:
            best_similarity = similarity
            best_idx = i
            best_sentence = sentence
        else:
          scores.append(-999)
      simScores.append(scores)

print()
print("="*50)
print("Best sentence: ", best_sentence)
print("Best score: ", best_similarity)