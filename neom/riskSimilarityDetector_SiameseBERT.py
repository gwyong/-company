# -*- coding: utf-8 -*-
"""riskSimilarityDetector_SiameseBERT

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GWilSYpAEtaUlj6x4R8vmXfLB6rfPM-Z

# Load SiameseBERT (please implement in Google Chrome environment.)
"""

! pip install ftfy regex tqdm
! pip install sentence-transformers

from sentence_transformers import SentenceTransformer

# Load the BERT model. Various models trained on Natural Language Inference (NLI) https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md and 
# Semantic Textual Similarity are available https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/sts-models.md

model = SentenceTransformer('bert-base-nli-mean-tokens')

"""# Load the RISK csv file"""

import pandas as pd
from google.colab import files
files.upload() # load dfEnablon.csv file.

df = pd.read_csv("./dfEnablon.csv")
df

"""# Receiving user's inputs."""

import scipy
import nltk
from nltk.tokenize import sent_tokenize
nltk.download('punkt')

import time
from tqdm import tqdm
targetCol = "Risk ~"

query = str(input())
query_embeddings = model.encode([query]) # size [1, 768]

totalDistances = []
best_idx = 0
best_distance = 1e+9 # setting a superlarge distance
best_sentence = ""

for i in tqdm(range(len(df)), desc="Similarity computing...", mininterval=0.5):
      time.sleep(0.1)
      distances = []
      contents = df[targetCol].iloc[i]
      sentences = sent_tokenize(contents)
      for sentence in sentences:
        sent_embeddings = model.encode([sentence])
        distance = scipy.spatial.distance.cdist(query_embeddings, sent1_embeddings, "cosine")[0][0]
        if distance < best_distance:
          best_distance = distance
          best_sentence = sentence
          best_idx = i
        distances.append(distance)
      totalDistances.append(distances)

print()
print("="*50)
print("Best sentence: ", best_sentence)
print("Best distance: ", best_distance)

"""# Easy example"""

import scipy

query = "Every morning, Paul eats an apple."
sent1 = "I usally eat an apple."
sent2 = "You want to buy apples in the market."
sent3 = "The Iron Curtain, which had divided Eastern and Western Europe for decades, had only just collapsed."
sent4 = "Theaters needed a hero, and they got one in a big way this weekend."

query_embeddings = model.encode([query])
sents = [sent1, sent2, sent3, sent4]
sents = [model.encode([sent]) for sent in sents]
dists = []
for sent_embeddings in sents:
      distance = scipy.spatial.distance.cdist(query_embeddings, sent_embeddings, "cosine")[0][0]
      dists.append(distance)
print(dists)